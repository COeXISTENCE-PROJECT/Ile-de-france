{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import janux \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = 'region_1'\n",
    "demand_file = f'inner_trips/{region_name}_inner.csv'\n",
    "\n",
    "region_name_mapping = json.load(open(\"region_name_mapping.json\"))\n",
    "region_name = region_name_mapping[region_name]\n",
    "\n",
    "min_start_time = 9 * 3600\n",
    "max_start_time = 10 * 3600\n",
    "\n",
    "PADDING = 0.001\n",
    "\n",
    "try_up_to_num_paths = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_osm = 'ile-de-france.osm.pbf'\n",
    "data_url = \"https://download.geofabrik.de/europe/france/ile-de-france-latest.osm.pbf\"\n",
    "download_osm_file(data_url, source_osm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = pd.read_csv(demand_file)\n",
    "demand_df = demand_df[[\"departure_time\",\"ox\",\"oy\",\"dx\",\"dy\"]]\n",
    "demand_df[\"dest_edge\"] = None\n",
    "demand_df[\"origin_edge\"] = None\n",
    "demand_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out departure times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = demand_df[demand_df[\"departure_time\"].between(min_start_time, max_start_time)]\n",
    "demand_df[\"departure_time\"] = demand_df[\"departure_time\"] - min_start_time\n",
    "demand_df[\"departure_time\"] = demand_df[\"departure_time\"].astype(int)\n",
    "demand_df = demand_df.reset_index(drop=True)\n",
    "\n",
    "print(len(demand_df))\n",
    "print(min(demand_df[\"departure_time\"]))\n",
    "print(max(demand_df[\"departure_time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = min(demand_df['oy'].min(), demand_df['dy'].min())\n",
    "max_y = max(demand_df['oy'].max(), demand_df['dy'].max())\n",
    "min_x = min(demand_df['ox'].min(), demand_df['dx'].min())\n",
    "max_x = max(demand_df['ox'].max(), demand_df['dx'].max())\n",
    "print(\"min_y: \", min_y)\n",
    "print(\"max_y: \", max_y)\n",
    "print(\"min_x: \", min_x)\n",
    "print(\"max_x: \", max_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_file = region_name + '/' + '.'.join([region_name, 'osm'])\n",
    "net_file = region_name + '/' + '.'.join([region_name, 'net', 'xml'])\n",
    "rou_file = region_name + '/' + '.'.join([region_name, 'rou', 'xml'])\n",
    "\n",
    "con_file = region_name + '/' + \".\".join([region_name, 'con' ,'xml'])\n",
    "edg_file = region_name + '/' + \".\".join([region_name, 'edg' ,'xml'])\n",
    "nod_file = region_name + '/' + \".\".join([region_name, 'nod' ,'xml'])\n",
    "tll_file = region_name + '/' + \".\".join([region_name, 'tll' ,'xml'])\n",
    "typ_file = region_name + '/' + \".\".join([region_name, 'typ' ,'xml'])\n",
    "\n",
    "if not os.path.exists(region_name):\n",
    "    os.makedirs(region_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_bbox(source_osm, osm_file, min_x-PADDING, min_y-PADDING, max_x+PADDING, max_y+PADDING)\n",
    "convert_osm_to_net(osm_file, net_file)\n",
    "convert_net_to_rou(net_file, rou_file)\n",
    "create_sumo_miscellaneous(region_name, net_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map demand to edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_xy = extract_nodes_from_osm(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = janux.visualizers.visualization_utils.parse_network_files(nod_file, edg_file)\n",
    "G = janux.visualizers.visualization_utils.create_graph(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_od_to_id = {}\n",
    "for o, d, edge_id in edges:\n",
    "    edges_od_to_id[(o, d)] = edge_id\n",
    "edges_id_to_od = {}\n",
    "for o, d, edge_id in edges:\n",
    "    edges_id_to_od[edge_id] = (o, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_xy = {}\n",
    "for o, d in G.edges():\n",
    "    try:\n",
    "        o_xy = node_xy[o]\n",
    "        d_xy = node_xy[d]\n",
    "        mid_xy = ((o_xy[0] + d_xy[0]) / 2, (o_xy[1] + d_xy[1]) / 2)\n",
    "        edges_xy[(o, d)] = mid_xy\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find non-dead-end origin candidates and accessible destination candidates\n",
    "network = janux.build_digraph(con_file, edg_file, rou_file)\n",
    "origin_candidates, destination_candidates = [], []\n",
    "for idx, node in enumerate(network.nodes()):\n",
    "    print(f\"\\rProcessing... {idx+1}/{len(network.nodes())}\", end=\"\")\n",
    "    # paths from nodes\n",
    "    paths_from = nx.descendants(network, node)\n",
    "    # paths to nodes\n",
    "    paths_to = nx.ancestors(network, node)\n",
    "    if len(paths_from) > 0:\n",
    "        origin_candidates.append(node)\n",
    "    if len(paths_to) > 0:\n",
    "        destination_candidates.append(node)\n",
    "print(\"\\norigin_candidates: \", len(origin_candidates))\n",
    "print(\"destination_candidates: \", len(destination_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in demand_df.iterrows():\n",
    "    print(f\"\\r{idx+1}/{len(demand_df)}\", end=\"\")\n",
    "    o_xy = (row['ox'], row['oy'])\n",
    "    d_xy = (row['dx'], row['dy'])\n",
    "    \n",
    "    # Find the closest edge to the origin from edges_xy\n",
    "    origin_edge = find_nearest_edge(row['ox'], row['oy'], origin_candidates, edges_xy, edges_id_to_od)\n",
    "    #origin_edge = edges_od_to_id.get(origin_edge, None)\n",
    "    dest_edge = find_nearest_edge(row['dx'], row['dy'], destination_candidates, edges_xy, edges_id_to_od)\n",
    "    #dest_edge = edges_od_to_id.get(dest_edge, None)\n",
    "    \n",
    "    if origin_edge is None or dest_edge is None:\n",
    "        raise ValueError(f\"Could not find nearest edge for origin ({row['ox']}, {row['oy']}) or destination ({row['dx']}, {row['dy']})\")\n",
    "    demand_df.at[idx, 'origin_edge'] = origin_edge\n",
    "    demand_df.at[idx, 'dest_edge'] = dest_edge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_demand = demand_df.sample(5)\n",
    "\n",
    "for idx, sample in sample_demand.iterrows():\n",
    "    print(f\"Demand origin x: {sample['ox']}, y: {sample['oy']} is mapped to edge {sample['origin_edge']}\")\n",
    "    print(f\"Demand destination x: {sample['dx']}, y: {sample['dy']} is mapped to edge {sample['dest_edge']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out undesirable ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = janux.build_digraph(con_file, edg_file, rou_file)\n",
    "\n",
    "demand_df.rename(columns={\"departure_time\": \"start_time\"}, inplace=True)\n",
    "demand_df.rename(columns={\"origin_edge\": \"origin\"}, inplace=True)\n",
    "demand_df.rename(columns={\"dest_edge\": \"destination\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Removing trips with inaccessible origins or destinations...\")\n",
    "\n",
    "origins, destinations = demand_df[\"origin\"].unique(), demand_df[\"destination\"].unique()\n",
    "bad_origins, bad_destinations = [], []\n",
    "reversed_network = network.reverse()\n",
    "\n",
    "# origins with no outlinks\n",
    "for idx, origin in enumerate(origins):\n",
    "    print(f\"\\r{idx+1}/{len(origins)}: Deleted: {len(bad_origins)}\", end=\"\")\n",
    "    try:\n",
    "        paths_from_origin = nx.multi_source_dijkstra_path(network, [origin])\n",
    "        del paths_from_origin[origin]\n",
    "        if len(paths_from_origin) == 0:\n",
    "            bad_origins.append(origin)\n",
    "    except:\n",
    "        bad_origins.append(origin)\n",
    " \n",
    "print(\"\\n\")\n",
    "# inaccessible destinations       \n",
    "for idx, destination in enumerate(destinations):\n",
    "    print(f\"\\r{idx+1}/{len(destinations)}: Deleted: {len(bad_destinations)}\", end=\"\")\n",
    "    try:\n",
    "        paths_from_destination = nx.multi_source_dijkstra_path(reversed_network, [destination])\n",
    "        del paths_from_destination[destination]\n",
    "        if len(paths_from_destination) == 0:\n",
    "            bad_destinations.append(destination)\n",
    "    except:\n",
    "        bad_destinations.append(destination)\n",
    "        \n",
    "for idx, row in demand_df.iterrows():\n",
    "    if row[\"origin\"] in bad_origins or row[\"destination\"] in bad_destinations:\n",
    "        demand_df.drop(idx, inplace=True)\n",
    "        \n",
    "print(f\"\\nDeleted {len(bad_origins)} origins and {len(bad_destinations)} destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Removing trips with identical origin and destination...\")\n",
    "counter = 0\n",
    "for idx, row in demand_df.iterrows():\n",
    "    if row[\"origin\"] == row[\"destination\"]:\n",
    "        demand_df.drop(idx, inplace=True)\n",
    "        counter += 1\n",
    "print(f\"Deleted {counter} trips with identical origin and destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.reset_index(drop=True, inplace=True)\n",
    "demand_df[\"id\"] = [i for i in range(len(demand_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune non-route-choice-able demand using JanuX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPruning demand with JanuX...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_demand = set()\n",
    "counter = 0\n",
    "\n",
    "for num_paths in range(try_up_to_num_paths):\n",
    "    results = route_gen_process(network, demand_df, num_paths+1, timeout=10)\n",
    "    for idx, row in demand_df.iterrows():\n",
    "        if (row[\"origin\"], row[\"destination\"]) in results:\n",
    "            demand_df.drop(idx, inplace=True)       \n",
    "            counter += 1\n",
    "    for d in results:\n",
    "        bad_demand.add(d)\n",
    "     \n",
    "bad_demand = list(bad_demand)\n",
    "print(f\"\\nOverall bad demands: {bad_demand}\")\n",
    "print(f\"Deleted {counter} trips with bad demand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indices\n",
    "demand_df.reset_index(drop=True, inplace=True)\n",
    "demand_df[\"id\"] = [i for i in range(len(demand_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn it into our format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_indices = {origin_name : idx for idx, origin_name in enumerate(demand_df[\"origin\"].unique())}\n",
    "destination_indices = {destination_name : idx for idx, destination_name in enumerate(demand_df[\"destination\"].unique())}\n",
    "\n",
    "origin_names = {value: key for key, value in origin_indices.items()}\n",
    "destination_names = {value: key for key, value in destination_indices.items()}\n",
    "\n",
    "for idx, row in demand_df.iterrows():\n",
    "    demand_df.at[idx, \"origin\"] = origin_indices[row[\"origin\"]]\n",
    "    demand_df.at[idx, \"destination\"] = destination_indices[row[\"destination\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.to_csv(f\"{region_name}/agents_{region_name}.csv\", index=False)\n",
    "print(\"Agents are saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Origins:\")\n",
    "keys = [k for k in origin_names.keys()]\n",
    "print(keys == sorted(keys))\n",
    "origins = [origin_names[k] for k in keys]\n",
    "print(origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Destinations:\")\n",
    "keys = [k for k in destination_names.keys()]\n",
    "print(keys == sorted(keys))\n",
    "destinations = [destination_names[k] for k in keys]\n",
    "print(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{region_name}/od_{region_name}.txt\"\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(f\"ORIGINS:\\n\")\n",
    "    f.write(f\"{origins}\\n\")\n",
    "    f.write(f\"DESTINATIONS:\\n\")\n",
    "    f.write(f\"{destinations}\\n\")\n",
    "print(f\"OD pairs are saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
